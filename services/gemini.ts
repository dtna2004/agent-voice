import { GoogleGenAI } from "@google/genai";

// Initialize Gemini Client
const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

/**
 * Transcribes audio blob to text using Gemini Flash.
 * Strictly configured for Vietnamese speech recognition.
 */
export const transcribeAudio = async (audioBlob: Blob): Promise<string> => {
  try {
    // Convert Blob to Base64
    const base64Audio = await blobToBase64(audioBlob);
    
    // Determine mime type (likely audio/webm or audio/mp4 depending on browser)
    const mimeType = audioBlob.type || 'audio/webm';

    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash',
      contents: {
        parts: [
          {
            inlineData: {
              mimeType: mimeType,
              data: base64Audio
            }
          },
          {
            text: `
              Bạn là một chuyên gia nhận dạng giọng nói Tiếng Việt.
              
              Nhiệm vụ:
              1. Nghe file âm thanh đính kèm.
              2. Chép lại CHÍNH XÁC những gì người dùng nói bằng Tiếng Việt.
              3. KHÔNG dịch sang tiếng Anh.
              4. Chỉ trả về nội dung văn bản thuần túy (không thêm dấu ngoặc, không giải thích).
              
              Ví dụ:
              Audio: "Thêm một con mèo vào ghế sofa" -> Output: "Thêm một con mèo vào ghế sofa"
            `
          }
        ]
      }
    });

    return response.text || "";
  } catch (error) {
    console.error("Transcription error:", error);
    throw new Error("Failed to transcribe audio.");
  }
};

/**
 * Edits an image based on a text prompt using Gemini Flash Image.
 */
export const editImage = async (base64Image: string, prompt: string): Promise<string> => {
  try {
    // Ensure the base64 string doesn't have the data URL prefix for the API call
    const cleanBase64 = base64Image.replace(/^data:image\/(png|jpeg|webp);base64,/, "");
    
    // We use gemini-2.5-flash-image for editing/generation tasks
    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash-image',
      contents: {
        parts: [
          {
            inlineData: {
              mimeType: 'image/png', // Assuming PNG for internal consistency
              data: cleanBase64
            }
          },
          {
            // We prepend a small hint to ensure the model treats it as an editing instruction
            // even if the Vietnamese prompt is short.
            text: `Thực hiện chỉnh sửa ảnh theo yêu cầu sau: ${prompt}`
          }
        ]
      }
    });

    // Extract the image from the response
    // The model may return text + image or just image. We look for inlineData.
    if (response.candidates && response.candidates[0].content.parts) {
      for (const part of response.candidates[0].content.parts) {
        if (part.inlineData && part.inlineData.data) {
          return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
        }
      }
    }
    
    throw new Error("No image generated by the model.");

  } catch (error) {
    console.error("Image editing error:", error);
    throw error;
  }
};

// Helper to convert Blob to Base64
const blobToBase64 = (blob: Blob): Promise<string> => {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onloadend = () => {
      const base64String = reader.result as string;
      // Remove the data URL prefix (e.g., "data:audio/webm;base64,") for the API if needed, 
      // but for the helper we usually want the raw base64 data part.
      // However, the helper above handles the prefix stripping for images manually.
      // For audio, we usually pass the prefix stripped version to 'data'.
      const base64Data = base64String.split(',')[1];
      resolve(base64Data);
    };
    reader.onerror = reject;
    reader.readAsDataURL(blob);
  });
};